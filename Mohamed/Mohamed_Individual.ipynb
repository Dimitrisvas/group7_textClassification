{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a890cb5e",
   "metadata": {},
   "source": [
    "# Individual experimentation belonging to:\n",
    "\n",
    "#### Mohamed Hassan \n",
    "#### URN: 6 \n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pickle\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Dropout, Conv1D, GlobalMaxPooling1D, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Constants\n",
    "EPOCHS = 30\n",
    "INIT_LR = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b919f3",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddfd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = \"train.csv\"\n",
    "TEST_DATA = \"test.csv\"\n",
    "TEST_LABELS = \"test_labels.csv\"\n",
    "REDUNDANT_FIELDS = [\"id\"]\n",
    "DATA_FIELD = [\"comment_text\"]\n",
    "LABEL_FIELDS = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "MAX_WORD = 200\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "N_SPLITS = 10\n",
    "N_REPEATS = 3\n",
    "RANDOM_STATE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf8cc3",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "\n",
    "ddd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f1b3f",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "fff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54005856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in training dataset\n",
    "train = pd.read_csv(TRAIN_DATASET)\n",
    "\n",
    "# Read in test data and labels\n",
    "test_data = pd.read_csv(TEST_DATA)\n",
    "test_labels = pd.read_csv(TEST_LABELS)\n",
    "\n",
    "# Combine test data and labels into one data frame\n",
    "test = pd.concat([test_data, test_labels], axis=1)\n",
    "\n",
    "# Remove redundant id field from both datasets\n",
    "train = train.drop(columns=REDUNDANT_FIELDS)\n",
    "test = test.drop(columns=REDUNDANT_FIELDS)\n",
    "\n",
    "# Remove samples with labels containing -1 in test dataset, this \n",
    "# is a place holder for samples that were not assigned labels.\n",
    "test = test.drop(test[(test.toxic == -1) |\n",
    "                      (test.severe_toxic == -1) |\n",
    "                      (test.obscene == -1) |\n",
    "                      (test.threat == -1) |\n",
    "                      (test.insult == -1) |\n",
    "                      (test.identity_hate == -1)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f65cd01",
   "metadata": {},
   "source": [
    "#### Here is how the training dataset looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3636f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5acff49",
   "metadata": {},
   "source": [
    "#### Here is how the test dataset looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ce540",
   "metadata": {},
   "source": [
    "### Class breakdown visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8aac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the data into a ...\n",
    "dataset = {}\n",
    "\n",
    "for index in range(1,7):\n",
    "    dataset.update({x.iloc[:,index].name : np.dataset(x.iloc[:,index], bins=2)[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c08f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ccf51",
   "metadata": {},
   "source": [
    "#### Visualising data spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of label spread\n",
    "df.plot(x ='labels', y='Is', kind = 'bar')\n",
    "\n",
    "plt.title('Number of messages associated with labels')\n",
    "plt.ylabel('Number of messages')\n",
    "plt.xlabel('Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c745cfb3",
   "metadata": {},
   "source": [
    "#### Average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds average word length for each label\n",
    "def calculate_average_word_length(doc):\n",
    "    # Construct a list that contains the word lengths for each DISTINCT word in the document\n",
    "    vocab_lengths = [len(i) for i in set(doc)] # TODO 4\n",
    "    # Find the average word type length\n",
    "    avg_vocab_length = sum(vocab_lengths) / len(vocab_lengths) # TODO 5\n",
    "\n",
    "    return avg_vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f412ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_avg = calculate_average_word_length(toxic_comments['comment_text'])\n",
    "severe_toxic_avg = calculate_average_word_length(severe_toxic_comments['comment_text'])\n",
    "threat_avg = calculate_average_word_length(threat_comments['comment_text'])\n",
    "identity_hate_avg= calculate_average_word_length(identity_hate_comments['comment_text'])\n",
    "obscene_avg= calculate_average_word_length(obscene_comments['comment_text'])\n",
    "insult_avg = calculate_average_word_length(insult_comments['comment_text'])\n",
    "\n",
    "\n",
    "df['average word-length'] = [toxic_avg, severe_toxic_avg, obscene_avg, threat_avg, insult_avg, identity_hate_avg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e32037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise average word length\n",
    "df.plot(x ='labels', y='average word-length', kind = 'bar')\n",
    "\n",
    "plt.title('Average word length')\n",
    "plt.ylabel('Number of messages')\n",
    "plt.xlabel('Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9199a",
   "metadata": {},
   "source": [
    "### Class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop toxic samples\n",
    "train = train.drop(train[(train.toxic == 1) & \n",
    "                          (train.severe_toxic != 1) & \n",
    "                          (train.threat != 1) & \n",
    "                          (train.obscene != 1) &\n",
    "                          (train.insult != 1) &\n",
    "                          (train.identity_hate != 1)].index[:6000])\n",
    "\n",
    "# Drop obscene samples\n",
    "train = train.drop(train[(train.toxic == 1) & \n",
    "                          (train.severe_toxic != 1) & \n",
    "                          (train.threat != 1) & \n",
    "                          (train.obscene == 1) &\n",
    "                          (train.insult != 1) &\n",
    "                          (train.identity_hate != 1)].index[:3000])\n",
    "\n",
    "# Drop insult samples\n",
    "train = train.drop(train[(train.toxic == 1) & \n",
    "                          (train.severe_toxic != 1) & \n",
    "                          (train.threat != 1) & \n",
    "                          (train.obscene != 1) &\n",
    "                          (train.insult == 1) &\n",
    "                          (train.identity_hate != 1)].index[:3000])\n",
    "\n",
    "# Drop non-toxic samples\n",
    "train = train.drop(train[(train.toxic != 1) & \n",
    "                          (train.severe_toxic != 1) & \n",
    "                          (train.threat != 1) & \n",
    "                          (train.obscene != 1) &\n",
    "                          (train.insult != 1) &\n",
    "                          (train.identity_hate != 1)].index[:100000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bbe330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d3bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9c69950",
   "metadata": {},
   "source": [
    "### Class spread visualisation after balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5f0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b4650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ea6dba2",
   "metadata": {},
   "source": [
    "### Cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a73f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "regex_str = \"[^a-zA-Z\\s]\"\n",
    "train['comment_text'] = train['comment_text'].replace(regex=regex_str, value=\"\")\n",
    "\n",
    "# Remove extra whitespaces\n",
    "regex_space = \"\\s+\"\n",
    "train['comment_text'] = train['comment_text'].replace(regex=regex_space, value=\" \")\n",
    "\n",
    "# Strip whitespaces\n",
    "train['comment_text'] = train['comment_text'].str.strip()\n",
    "\n",
    "# Lowercase\n",
    "train['comment_text'] = train['comment_text'].str.lower()\n",
    "\n",
    "# Convert comment_text column into a list\n",
    "comment_list = train['comment_text'].tolist()\n",
    "\n",
    "print(comment_list[898])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7628c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350cc74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e9e02ac",
   "metadata": {},
   "source": [
    "### Stopword removal\n",
    "\n",
    "To remove the stopwords a list of word ... <br>\n",
    "The stopword list used here is the base with the upcoming stopword lists experiments using different stopword lists such as ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bbf37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords, using stopword list from nltk\n",
    "stopword_list = set(stopwords.words('english'))\n",
    "removed_stopwords = [word for word in tokenised_comment if word not in stopword_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f019c9",
   "metadata": {},
   "source": [
    "### Visualisation of top stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd1c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def plot_top_stopwords_barchart(text):\n",
    "    stop=set(stopwords.words('english'))\n",
    "    \n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "    from collections import defaultdict\n",
    "    dic=defaultdict(int)\n",
    "        if word in stop:\n",
    "            dic[word]+=1\n",
    "            \n",
    "    top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "    x,y=zip(*top)\n",
    "    plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_stopwords_barchart(x['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abaf7ec",
   "metadata": {},
   "source": [
    "### Visualisation of top most frequent words after stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0843336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import  Counter\n",
    "\n",
    "def plot_top_non_stopwords_barchart(text):\n",
    "    stop=set(stopwords.words('english'))\n",
    "    \n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    counter=Counter(corpus)\n",
    "    most=counter.most_common()\n",
    "    x, y=[], []\n",
    "    for word,count in most[:40]:\n",
    "        if (word not in stop):\n",
    "            x.append(word)\n",
    "            y.append(count)\n",
    "            \n",
    "    sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c24c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_non_stopwords_barchart(x['comment_text'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0517a0",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e9058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim N-grams\n",
    "# Create bigram model\n",
    "bigram = Phrases(comment_token, min_count=5, threshold=100)\n",
    "bigram_model = Phraser(bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf8d8b",
   "metadata": {},
   "source": [
    "### Visualisation of top N-grams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84758993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_top_ngrams_barchart(text, n=2):\n",
    "    stop=set(stopwords.words('english'))\n",
    "\n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    def _get_top_ngram(corpus, n=None):\n",
    "        vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "        bag_of_words = vec.transform(corpus)\n",
    "        sum_words = bag_of_words.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) \n",
    "                      for word, idx in vec.vocabulary_.items()]\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return words_freq[:10]\n",
    "\n",
    "    top_n_bigrams=_get_top_ngram(text,n)[:10]\n",
    "    x,y=map(list,zip(*top_n_bigrams))\n",
    "    sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28662f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_ngrams_barchart(x['comment_text'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f2ef69",
   "metadata": {},
   "source": [
    "### Tokenise dataset \n",
    "\n",
    "This is done ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6fbe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize function\n",
    "def tokenize(text):\n",
    "    return [word_tokenize(word) for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e43dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert comment_text column into a list\n",
    "comment_list = train_dataset['comment_text'].tolist()\n",
    "\n",
    "# Tokenize\n",
    "comment_token = tokenize(comment_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691fe35b",
   "metadata": {},
   "source": [
    "### Lemmatisation \n",
    "\n",
    "Here we will be applying ...\n",
    "One of the upcoming experiments will be implementing different stemmers to determine which has the best ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa8b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    # now we need to convert from nltk to wordnet POS notations (for compatibility reasons)\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN) # return and default to noun if not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b2313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "comment_lemma = []\n",
    "for comment in comment_token_stop:\n",
    "    temp = []\n",
    "    temp.append([lemmatizer.lemmatize(word, pos=get_wordnet_pos(word)) for word in comment])\n",
    "    comment_lemma += temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e1ba5",
   "metadata": {},
   "source": [
    "### Saving preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdedead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lemmatised tokens\n",
    "pickle.dump(comment_lemma, open(\"comment_lemma.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c439a9",
   "metadata": {},
   "source": [
    "### Wordcloud visualisation \n",
    "\n",
    "ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef4746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b274dc0",
   "metadata": {},
   "source": [
    "### Heatmap visualisation \n",
    "\n",
    "ffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03ab4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5758827c",
   "metadata": {},
   "source": [
    "# Model \n",
    "\n",
    "The model ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519e9a25",
   "metadata": {},
   "source": [
    "### Building model\n",
    "\n",
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_words):\n",
    "    EPOCHS = 30\n",
    "    INIT_LR = 1e-3\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(num_words, 128))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3))\n",
    "    model.add(Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    adam = tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer=adam,\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f063f",
   "metadata": {},
   "source": [
    "### ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 20000\n",
    "max_len = 80\n",
    "\n",
    "tokenizer = Tokenizer(num_words)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "corpus = tokenizer.word_index\n",
    "reverse_corpus = dict(map(reversed, corpus.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c30388",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_padded_train = keras.preprocessing.sequence.pad_sequences(x_sequences_train, maxlen=max_len)\n",
    "x_padded_train = np.array(x_padded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aff3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_pickle('balanced_dataset.pickle')\n",
    "y = y.drop(columns=\"comment_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b1a8c",
   "metadata": {},
   "source": [
    "### Model compilation\n",
    "\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a7ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_padded_train, y, batch_size=60, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba58b538",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f157cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('base_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9309ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('base_model')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdede231",
   "metadata": {},
   "source": [
    "# Experiment 1 - Stemmers \n",
    "\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54e128",
   "metadata": {},
   "source": [
    "### Experiment 1.1 - Snowball stemmer\n",
    "\n",
    "ffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435eb161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "526e531b",
   "metadata": {},
   "source": [
    "### Compiling experiments\n",
    "\n",
    "fggg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688c364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a480aba",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "ffff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9390b80a",
   "metadata": {},
   "source": [
    "# Experiment 2 - Stopword\n",
    "\n",
    "ff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dfc72b",
   "metadata": {},
   "source": [
    "### Experiment 2.1 - Snowball stemmer\n",
    "\n",
    "ffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e3a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f302c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b3ab599",
   "metadata": {},
   "source": [
    "### Compiling experiments\n",
    "\n",
    "fggg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45601e3",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "ffff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725cdceb",
   "metadata": {},
   "source": [
    "# Experiment 3 - Spelling correction \n",
    "\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422dcb73",
   "metadata": {},
   "source": [
    "### Experiment 3.1 - Snowball stemmer\n",
    "\n",
    "ffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89598d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73d0d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3990e1b2",
   "metadata": {},
   "source": [
    "### Compiling experiments\n",
    "\n",
    "fggg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0064e10c",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "ffff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5a97d",
   "metadata": {},
   "source": [
    "# Experiment 4 - ??? \n",
    "\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f75079",
   "metadata": {},
   "source": [
    "### Experiment 4.1 - Snowball stemmer\n",
    "\n",
    "ffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3ed0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a2b58b6",
   "metadata": {},
   "source": [
    "### Compiling experiments\n",
    "\n",
    "fggg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb92ac",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "ffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim N-grams\n",
    "# Create bigram model\n",
    "bigram = Phrases(comment_token, min_count=5, threshold=100)\n",
    "bigram_model = Phraser(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e00893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "comment_stop = [word for word in comment_list if word not in STOP_WORDS]\n",
    "\n",
    "# Tokenize stopwords removed\n",
    "comment_token_stop = tokenize(comment_stop)\n",
    "\n",
    "# Create Gensim n-grams\n",
    "comment_bigrams = [bigram_model[word] for word in comment_token_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmers implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6cda97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10291c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab376d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7be9d61e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 20000\n",
    "max_len = 80\n",
    "\n",
    "tokenizer = Tokenizer(num_words)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "corpus = tokenizer.word_index\n",
    "reverse_corpus = dict(map(reversed, corpus.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_padded_train = keras.preprocessing.sequence.pad_sequences(x_sequences_train, maxlen=max_len)\n",
    "x_padded_train = np.array(x_padded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f186714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_pickle('balanced_dataset.pickle')\n",
    "y = y.drop(columns=\"comment_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b396d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.build_model(num_words)\n",
    "\n",
    "model.fit(x_padded_train, y, batch_size=60, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('base_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a17dd10",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4435fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "TEST_DATA = \"test.csv\"\n",
    "TEST_LABELS = \"test_labels.csv\"\n",
    "DATA_FIELD = [\"id\",\"comment_text\"]\n",
    "LABEL_FIELDS = [\"id\",\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "REDUNDANT_FIELDS = [\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9388750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in model\n",
    "model = utils.build_model(20000)\n",
    "model.summary()\n",
    "\n",
    "# make predictions on model\n",
    "test_data = pd.read_csv(TEST_DATA)\n",
    "test_labels = pd.read_csv(TEST_LABELS)\n",
    "\n",
    "# Combine test data and labels into one data frame\n",
    "test_dataset = pd.concat([test_data, test_labels], axis=1)\n",
    "\n",
    "# Remove redundant id field \n",
    "test_dataset = test_dataset.drop(columns=REDUNDANT_FIELDS)\n",
    "\n",
    "# Remove samples with labels containing -1 in test dataset, this \n",
    "# is a place holder for samples that were not assigned labels.\n",
    "test_dataset = test_dataset.drop(test_dataset[(test_dataset.toxic == -1) |\n",
    "                                              (test_dataset.severe_toxic == -1) |\n",
    "                                              (test_dataset.obscene == -1) |\n",
    "                                              (test_dataset.threat == -1) |\n",
    "                                              (test_dataset.insult == -1) |\n",
    "                                              (test_dataset.identity_hate == -1)].index)\n",
    "\n",
    "x_test = test_dataset[\"comment_text\"]\n",
    "y_true = test_dataset[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]]\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(20000)\n",
    "tokenizer.fit_on_texts(x_test)\n",
    "corpus = tokenizer.word_index\n",
    "reverse_corpus = dict(map(reversed, corpus.items()))\n",
    "\n",
    "x_sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_padded_test = keras.preprocessing.sequence.pad_sequences(x_sequences_test, maxlen= 150)\n",
    "x_padded_test = np.array(x_padded_test)\n",
    "\n",
    "print(\"Shape of test data:\", x_padded_test.shape)\n",
    "print(\"Shape of test labels:\", y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d13114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_padded_test).round()\n",
    "y_pred = y_pred.astype(int)\n",
    "\n",
    "print(y_pred[7])\n",
    "print(y_true.values[7])\n",
    "print(y_pred)\n",
    "print(y_true.values)\n",
    "\n",
    "f1 = f1_score(y_true.values, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(\"F1: \", f1)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e20d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(6):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true.values[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(6):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ebcb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167edb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b16110d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
