{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extensive-allah",
   "metadata": {},
   "source": [
    " # Individual Experimentation\n",
    " Name: Vinal Asodia <br>\n",
    " Username: va00191 <br>\n",
    " URN: 6539526\n",
    " \n",
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nutritional-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import keras\n",
    "import h5py\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Conv1D, Dropout, Conv1D, GlobalMaxPooling1D, Embedding, LSTM, SpatialDropout1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-logging",
   "metadata": {},
   "source": [
    "#### Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "another-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = \"train.csv\"\n",
    "TEST_DATA = \"test.csv\"\n",
    "TEST_LABELS = \"test_labels.csv\"\n",
    "REDUNDANT_FIELDS = [\"id\"]\n",
    "DATA_FIELD = [\"comment_text\"]\n",
    "LABEL_FIELDS = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "MAX_WORD = 200\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "N_SPLITS = 10\n",
    "N_REPEATS = 3\n",
    "RANDOM_STATE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-caribbean",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-department",
   "metadata": {},
   "source": [
    "#### Read in the dataset\n",
    "The dataset can be download here (https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) <br>\n",
    "The dataset comes in 3 csv files, the training dataset, the test comments and the test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "combined-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in training dataset\n",
    "train = pd.read_csv(TRAIN_DATASET)\n",
    "\n",
    "# Read in test data and labels\n",
    "test_data = pd.read_csv(TEST_DATA)\n",
    "test_labels = pd.read_csv(TEST_LABELS)\n",
    "\n",
    "# Combine test data and labels into one data frame\n",
    "test = pd.concat([test_data, test_labels], axis=1)\n",
    "\n",
    "# Remove redundant id field from both datasets\n",
    "train = train.drop(columns=REDUNDANT_FIELDS)\n",
    "test = test.drop(columns=REDUNDANT_FIELDS)\n",
    "\n",
    "# Remove samples with labels containing -1 in test dataset, this \n",
    "# is a place holder for samples that were not assigned labels.\n",
    "test = test.drop(test[(test.toxic == -1) |\n",
    "                      (test.severe_toxic == -1) |\n",
    "                      (test.obscene == -1) |\n",
    "                      (test.threat == -1) |\n",
    "                      (test.insult == -1) |\n",
    "                      (test.identity_hate == -1)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-essay",
   "metadata": {},
   "source": [
    "#### Normalise and Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "immune-trademark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "regex_str = \"[^a-zA-Z\\s]\"\n",
    "train['comment_text'] = train['comment_text'].replace(regex=regex_str, value=\"\")\n",
    "\n",
    "# Remove extra whitespaces\n",
    "regex_space = \"\\s+\"\n",
    "train['comment_text'] = train['comment_text'].replace(regex=regex_space, value=\" \")\n",
    "\n",
    "# Strip whitespaces\n",
    "train['comment_text'] = train['comment_text'].str.strip()\n",
    "\n",
    "# Lowercase\n",
    "train['comment_text'] = train['comment_text'].str.lower()\n",
    "\n",
    "# Convert comment_text column into a list\n",
    "comment_list = train['comment_text'].tolist()\n",
    "\n",
    "print(len(comment_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "medieval-tower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['explanation', 'why', 'the', 'edits', 'made', 'under', 'my', 'username', 'hardcore', 'metallica', 'fan', 'were', 'reverted', 'they', 'werent', 'vandalisms', 'just', 'closure', 'on', 'some', 'gas', 'after', 'i', 'voted', 'at', 'new', 'york', 'dolls', 'fac', 'and', 'please', 'dont', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'im', 'retired', 'now', 'daww', 'he', 'matches', 'this', 'background', 'colour', 'im', 'seemingly', 'stuck', 'with', 'thanks', 'talk', 'january', 'utc', 'hey', 'man', 'im', 'really', 'not', 'trying', 'to', 'edit', 'war', 'its', 'just', 'that', 'this', 'guy', 'is', 'constantly', 'removing', 'relevant', 'information', 'and', 'talking', 'to', 'me', 'through', 'edits', 'instead', 'of', 'my', 'talk', 'page', 'he', 'seems', 'to', 'care', 'more', 'about', 'the', 'formatting', 'than', 'the', 'actual', 'info', 'more', 'i', 'cant', 'make', 'any', 'real', 'suggestions', 'on', 'improvement', 'i', 'wondered', 'if', 'the', 'section', 'statistics', 'should', 'be', 'later', 'on', 'or', 'a', 'subsection', 'of', 'types', 'of', 'accidents', 'i', 'think', 'the', 'references', 'may', 'need', 'tidying', 'so', 'that', 'they', 'are', 'all', 'in', 'the', 'exact', 'same', 'format', 'ie', 'date', 'format', 'etc', 'i', 'can', 'do', 'that', 'later', 'on', 'if', 'noone', 'else', 'does', 'first', 'if', 'you', 'have', 'any', 'preferences', 'for', 'formatting', 'style', 'on', 'references', 'or', 'want', 'to', 'do', 'it', 'yourself', 'please', 'let', 'me', 'know', 'there', 'appears', 'to', 'be', 'a', 'backlog', 'on', 'articles', 'for', 'review', 'so', 'i', 'guess', 'there', 'may', 'be', 'a', 'delay', 'until', 'a', 'reviewer', 'turns', 'up']\n"
     ]
    }
   ],
   "source": [
    "comments = [sentence.split() for sentence in comment_list]\n",
    "tokenised_comment = [word for sentence in comments for word in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-belarus",
   "metadata": {},
   "source": [
    "#### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "associate-japan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5463485\n",
      "10445524\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords, using stopword list from nltk\n",
    "stopword_list = set(stopwords.words('english'))\n",
    "removed_stopwords = [word for word in tokenised_comment if word not in stopword_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-aquatic",
   "metadata": {},
   "source": [
    "#### Visualise the initial class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-salem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "organized-angola",
   "metadata": {},
   "source": [
    "#### Balance the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-chapter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "oriented-vatican",
   "metadata": {},
   "source": [
    "#### Visualise the new class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-hartford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bridal-standing",
   "metadata": {},
   "source": [
    "#### Visualise the top words for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-puzzle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-background",
   "metadata": {},
   "source": [
    "#### Create N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-agriculture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sustained-answer",
   "metadata": {},
   "source": [
    "#### Visualise the Top N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-tobago",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "growing-vocabulary",
   "metadata": {},
   "source": [
    "#### Tokenise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-violence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "naval-riding",
   "metadata": {},
   "source": [
    "#### Lemmatise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-lesson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "awful-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = utils.read_datasets()\n",
    "x_train = pickle.load(open(\"comment_lemma.pickle\", \"rb\"))\n",
    "y_train = train[LABEL_FIELDS]\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "tokenizer = Tokenizer(NUM_WORDS)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "corpus = tokenizer.word_index\n",
    "reverse_corpus = dict(map(reversed, corpus.items()))\n",
    "\n",
    "x_sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_padded_train = keras.preprocessing.sequence.pad_sequences(x_sequences_train, maxlen= 150)\n",
    "x_padded_train = np.array(x_padded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adapted-tablet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-capital",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "breathing-switzerland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"embedding_3_input:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 150).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"embedding_3_input:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 150).\n",
      "101/101 [==============================] - ETA: 0s - loss: 0.5068 - accuracy: 0.3920WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"embedding_3_input:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 150).\n",
      "101/101 [==============================] - 34s 333ms/step - loss: 0.5068 - accuracy: 0.3920 - val_loss: 0.1232 - val_accuracy: 0.0322\n",
      "Epoch 2/5\n",
      "101/101 [==============================] - 36s 360ms/step - loss: 0.3169 - accuracy: 0.4487 - val_loss: 0.0609 - val_accuracy: 0.0350\n",
      "Epoch 3/5\n",
      "101/101 [==============================] - 36s 360ms/step - loss: 0.2737 - accuracy: 0.4381 - val_loss: 0.0692 - val_accuracy: 0.1485\n",
      "Epoch 4/5\n",
      "101/101 [==============================] - 37s 364ms/step - loss: 0.2375 - accuracy: 0.4603 - val_loss: 0.0336 - val_accuracy: 0.0518\n",
      "Epoch 5/5\n",
      "101/101 [==============================] - 37s 367ms/step - loss: 0.1996 - accuracy: 0.3956 - val_loss: 0.0303 - val_accuracy: 0.0560\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(NUM_WORDS, EMBEDDING_DIM, input_length=200))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(x_padded_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-singles",
   "metadata": {},
   "source": [
    " # Leave One Out Cross Validation (LOOCV)\n",
    " Too many samples to use LOOCV, takes roughly 4.5 minutes for 1 sample.... for roughly 7200 samples it would take 32,400 minutes, which 540 hours, which is 22.5 days..... yeah no\n",
    " \n",
    " One work around could be lower the number of epochs and increase the batch size, but maybe just move onto other cross validation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-photography",
   "metadata": {},
   "source": [
    "# Experiment Setup 1: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "incorporate-distinction",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "201/201 [==============================] - 11s 55ms/step - loss: 0.4968 - accuracy: 0.3375\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 11s 56ms/step - loss: 0.3659 - accuracy: 0.4227\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 59ms/step - loss: 0.3238 - accuracy: 0.4434\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 12s 58ms/step - loss: 0.3007 - accuracy: 0.4570\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 62ms/step - loss: 0.2889 - accuracy: 0.4645\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.2757 - accuracy: 0.4794\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 13s 62ms/step - loss: 0.2639 - accuracy: 0.4816\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.2513 - accuracy: 0.4945\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.2367 - accuracy: 0.4908\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.2230 - accuracy: 0.4972\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4430 - accuracy: 0.4720\n",
      "Loss:  0.44302573800086975\n",
      "Accuracy:  0.4719887971878052\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.2409 - accuracy: 0.4822\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.2130 - accuracy: 0.4852\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.2004 - accuracy: 0.4874\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1874 - accuracy: 0.4793\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1793 - accuracy: 0.4695\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 14s 69ms/step - loss: 0.1719 - accuracy: 0.4586\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1636 - accuracy: 0.4557\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1579 - accuracy: 0.4452\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1566 - accuracy: 0.4308\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 14s 69ms/step - loss: 0.1521 - accuracy: 0.4305\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2406 - accuracy: 0.4454\n",
      "Loss:  0.24055352807044983\n",
      "Accuracy:  0.4453781545162201\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1616 - accuracy: 0.4228\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1544 - accuracy: 0.4111\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1455 - accuracy: 0.4117\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1421 - accuracy: 0.4139\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1394 - accuracy: 0.4021\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 13s 67ms/step - loss: 0.1359 - accuracy: 0.3744\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 13s 67ms/step - loss: 0.1347 - accuracy: 0.3881\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1320 - accuracy: 0.3963\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1312 - accuracy: 0.3790\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 15s 74ms/step - loss: 0.1292 - accuracy: 0.3881\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1455 - accuracy: 0.4194\n",
      "Loss:  0.14551974833011627\n",
      "Accuracy:  0.4193548262119293\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 14s 72ms/step - loss: 0.1324 - accuracy: 0.3948\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 14s 70ms/step - loss: 0.1286 - accuracy: 0.3630\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1262 - accuracy: 0.3812\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 15s 73ms/step - loss: 0.1248 - accuracy: 0.3803\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1231 - accuracy: 0.3835\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1222 - accuracy: 0.3907\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1218 - accuracy: 0.3850\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1207 - accuracy: 0.3716\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1215 - accuracy: 0.3865\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1199 - accuracy: 0.3859\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.50 - 0s 8ms/step - loss: 0.1360 - accuracy: 0.4684\n",
      "Loss:  0.13599838316440582\n",
      "Accuracy:  0.4684431850910187\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1208 - accuracy: 0.3968\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1210 - accuracy: 0.3770\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 14s 68ms/step - loss: 0.1174 - accuracy: 0.3853\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 15s 72ms/step - loss: 0.1163 - accuracy: 0.3818\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 15s 73ms/step - loss: 0.1151 - accuracy: 0.3971\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 15s 75ms/step - loss: 0.1153 - accuracy: 0.3968\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 15s 73ms/step - loss: 0.1168 - accuracy: 0.3730\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1137 - accuracy: 0.3876\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1130 - accuracy: 0.3921\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1135 - accuracy: 0.3857\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1250 - accuracy: 0.4530\n",
      "Loss:  0.12497672438621521\n",
      "Accuracy:  0.45301541686058044\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 14s 71ms/step - loss: 0.1177 - accuracy: 0.3971\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 15s 77ms/step - loss: 0.1141 - accuracy: 0.3963\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 15s 74ms/step - loss: 0.1149 - accuracy: 0.4015\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 15s 76ms/step - loss: 0.1131 - accuracy: 0.4061\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 15s 76ms/step - loss: 0.1151 - accuracy: 0.4032\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 14s 69ms/step - loss: 0.1129 - accuracy: 0.3878\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 14s 71ms/step - loss: 0.1120 - accuracy: 0.4079\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 14s 69ms/step - loss: 0.1138 - accuracy: 0.3999\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 14s 67ms/step - loss: 0.1122 - accuracy: 0.4086\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 14s 69ms/step - loss: 0.1120 - accuracy: 0.4105\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1138 - accuracy: 0.4446\n",
      "Loss:  0.11378948390483856\n",
      "Accuracy:  0.44460028409957886\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1136 - accuracy: 0.3859\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 14s 71ms/step - loss: 0.1118 - accuracy: 0.3979\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 15s 75ms/step - loss: 0.1115 - accuracy: 0.3951\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 14s 69ms/step - loss: 0.1105 - accuracy: 0.4030\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 15s 74ms/step - loss: 0.1111 - accuracy: 0.3864\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 14s 68ms/step - loss: 0.1116 - accuracy: 0.4004\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 16s 82ms/step - loss: 0.1099 - accuracy: 0.3977\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 15s 75ms/step - loss: 0.1112 - accuracy: 0.4083\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 14s 70ms/step - loss: 0.1109 - accuracy: 0.4040\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 14s 68ms/step - loss: 0.1097 - accuracy: 0.4086\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1088 - accuracy: 0.4516\n",
      "Loss:  0.10877855122089386\n",
      "Accuracy:  0.4516128897666931\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 14s 68ms/step - loss: 0.1132 - accuracy: 0.4228\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 14s 67ms/step - loss: 0.1143 - accuracy: 0.4202\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 14s 71ms/step - loss: 0.1129 - accuracy: 0.4135\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 14s 70ms/step - loss: 0.1127 - accuracy: 0.4138\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 14s 71ms/step - loss: 0.1121 - accuracy: 0.3949\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 14s 69ms/step - loss: 0.1121 - accuracy: 0.3979\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 14s 68ms/step - loss: 0.1110 - accuracy: 0.3965\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 16s 77ms/step - loss: 0.1112 - accuracy: 0.3921\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 16s 78ms/step - loss: 0.1107 - accuracy: 0.3957\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 15s 74ms/step - loss: 0.1109 - accuracy: 0.4058\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0835 - accuracy: 0.3983\n",
      "Loss:  0.0835021361708641\n",
      "Accuracy:  0.39831697940826416\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 15s 72ms/step - loss: 0.1082 - accuracy: 0.3998\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 15s 72ms/step - loss: 0.1082 - accuracy: 0.4177\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 14s 72ms/step - loss: 0.1074 - accuracy: 0.4122\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 15s 73ms/step - loss: 0.1072 - accuracy: 0.3955\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 14s 72ms/step - loss: 0.1058 - accuracy: 0.3927\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 14s 71ms/step - loss: 0.1061 - accuracy: 0.4063\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 16s 78ms/step - loss: 0.1069 - accuracy: 0.3959\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 16s 78ms/step - loss: 0.1066 - accuracy: 0.4008\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1051 - accuracy: 0.3957\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 14s 70ms/step - loss: 0.1076 - accuracy: 0.3906\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.1118 - accuracy: 0.3913\n",
      "Loss:  0.11183485388755798\n",
      "Accuracy:  0.3913043439388275\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 67ms/step - loss: 0.1097 - accuracy: 0.3948\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 14s 69ms/step - loss: 0.1085 - accuracy: 0.3848\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 14s 67ms/step - loss: 0.1085 - accuracy: 0.3979\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 14s 69ms/step - loss: 0.1073 - accuracy: 0.3983\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 14s 71ms/step - loss: 0.1068 - accuracy: 0.3979\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 14s 71ms/step - loss: 0.1064 - accuracy: 0.3948\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1072 - accuracy: 0.3951\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 14s 70ms/step - loss: 0.1060 - accuracy: 0.4063\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 16s 78ms/step - loss: 0.1049 - accuracy: 0.4121\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 67ms/step - loss: 0.1068 - accuracy: 0.4128\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1119 - accuracy: 0.4039\n",
      "Loss:  0.11192391067743301\n",
      "Accuracy:  0.4039270579814911\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1077 - accuracy: 0.4190\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 14s 72ms/step - loss: 0.1075 - accuracy: 0.4123\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 14s 70ms/step - loss: 0.1073 - accuracy: 0.4162\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 14s 72ms/step - loss: 0.1061 - accuracy: 0.3886\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 14s 72ms/step - loss: 0.1062 - accuracy: 0.4070\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 15s 73ms/step - loss: 0.1063 - accuracy: 0.4079\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 15s 75ms/step - loss: 0.1071 - accuracy: 0.3942\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1045 - accuracy: 0.3951\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 62ms/step - loss: 0.1060 - accuracy: 0.3976\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1064 - accuracy: 0.4039\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1024 - accuracy: 0.4832\n",
      "Loss:  0.10238844901323318\n",
      "Accuracy:  0.4831932783126831\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1078 - accuracy: 0.4117\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1061 - accuracy: 0.4098\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 14s 71ms/step - loss: 0.1056 - accuracy: 0.4032\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1043 - accuracy: 0.4034\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1041 - accuracy: 0.3894\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1044 - accuracy: 0.4001\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1045 - accuracy: 0.3970\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1071 - accuracy: 0.3970\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1035 - accuracy: 0.3900\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1047 - accuracy: 0.4046\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1102 - accuracy: 0.4412\n",
      "Loss:  0.11018198728561401\n",
      "Accuracy:  0.44117647409439087\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 12s 60ms/step - loss: 0.1031 - accuracy: 0.3963\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1012 - accuracy: 0.3879\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1010 - accuracy: 0.3990\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 14s 67ms/step - loss: 0.1029 - accuracy: 0.4004\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1016 - accuracy: 0.3924\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1017 - accuracy: 0.4077\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1021 - accuracy: 0.4063\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1025 - accuracy: 0.4121\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1028 - accuracy: 0.4016\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1017 - accuracy: 0.4044\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1273 - accuracy: 0.4544\n",
      "Loss:  0.12731702625751495\n",
      "Accuracy:  0.4544179439544678\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1050 - accuracy: 0.3968\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 12s 60ms/step - loss: 0.1056 - accuracy: 0.3826\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 13s 67ms/step - loss: 0.1053 - accuracy: 0.3960\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1035 - accuracy: 0.4035\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 14s 71ms/step - loss: 0.1045 - accuracy: 0.4054\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1047 - accuracy: 0.4001\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1045 - accuracy: 0.4066\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1033 - accuracy: 0.4161\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1035 - accuracy: 0.3892\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 14s 68ms/step - loss: 0.1041 - accuracy: 0.4030\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1018 - accuracy: 0.4123\n",
      "Loss:  0.10176672786474228\n",
      "Accuracy:  0.41234222054481506\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 67ms/step - loss: 0.1022 - accuracy: 0.4071\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 14s 68ms/step - loss: 0.1031 - accuracy: 0.4100\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1021 - accuracy: 0.4080\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1015 - accuracy: 0.4174\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1011 - accuracy: 0.3993\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1015 - accuracy: 0.3971\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 14s 68ms/step - loss: 0.1037 - accuracy: 0.3949\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 12s 59ms/step - loss: 0.1016 - accuracy: 0.3932\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1022 - accuracy: 0.4021\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1017 - accuracy: 0.4055\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1215 - accuracy: 0.4165\n",
      "Loss:  0.12145358324050903\n",
      "Accuracy:  0.41654980182647705\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1044 - accuracy: 0.4063\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1027 - accuracy: 0.4155\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1030 - accuracy: 0.4119\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1027 - accuracy: 0.4230\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1038 - accuracy: 0.4032\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1031 - accuracy: 0.4058\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1033 - accuracy: 0.4258\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1028 - accuracy: 0.4192\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1025 - accuracy: 0.4189\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1035 - accuracy: 0.4205\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1053 - accuracy: 0.3927\n",
      "Loss:  0.10529401153326035\n",
      "Accuracy:  0.39270687103271484\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1037 - accuracy: 0.4138\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1054 - accuracy: 0.4181\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 15s 75ms/step - loss: 0.1049 - accuracy: 0.4318\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1043 - accuracy: 0.4265\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1043 - accuracy: 0.4328\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 15s 75ms/step - loss: 0.1034 - accuracy: 0.4251\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 15s 77ms/step - loss: 0.1060 - accuracy: 0.4156\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 14s 70ms/step - loss: 0.1037 - accuracy: 0.4110\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1042 - accuracy: 0.4085\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 67ms/step - loss: 0.1039 - accuracy: 0.4205\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0914 - accuracy: 0.4025\n",
      "Loss:  0.09135405719280243\n",
      "Accuracy:  0.40252453088760376\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1046 - accuracy: 0.4015\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1047 - accuracy: 0.4170\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1049 - accuracy: 0.4198\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 14s 68ms/step - loss: 0.1044 - accuracy: 0.4320\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1040 - accuracy: 0.4083\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 12s 59ms/step - loss: 0.1033 - accuracy: 0.4152\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 13s 62ms/step - loss: 0.1040 - accuracy: 0.4323\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 62ms/step - loss: 0.1042 - accuracy: 0.4012\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 62ms/step - loss: 0.1036 - accuracy: 0.4093\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1038 - accuracy: 0.4072\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0921 - accuracy: 0.3843\n",
      "Loss:  0.09212334454059601\n",
      "Accuracy:  0.38429173827171326\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1024 - accuracy: 0.4049\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1032 - accuracy: 0.4111\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1022 - accuracy: 0.4030\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1032 - accuracy: 0.4174\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1021 - accuracy: 0.4186\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1025 - accuracy: 0.4161\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 12s 58ms/step - loss: 0.1025 - accuracy: 0.4135\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1022 - accuracy: 0.4153\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1019 - accuracy: 0.4122\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1022 - accuracy: 0.4211\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1016 - accuracy: 0.4250\n",
      "Loss:  0.10163766145706177\n",
      "Accuracy:  0.42496493458747864\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 12s 58ms/step - loss: 0.1041 - accuracy: 0.4117\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1047 - accuracy: 0.4144\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1034 - accuracy: 0.4043\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1032 - accuracy: 0.4058\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1031 - accuracy: 0.4133\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 12s 57ms/step - loss: 0.1033 - accuracy: 0.4183\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1037 - accuracy: 0.4250\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1028 - accuracy: 0.4247\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1037 - accuracy: 0.4183\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 12s 58ms/step - loss: 0.1029 - accuracy: 0.4096\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0877 - accuracy: 0.3997\n",
      "Loss:  0.08766987919807434\n",
      "Accuracy:  0.3997195065021515\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1025 - accuracy: 0.4104\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1038 - accuracy: 0.4182\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 60ms/step - loss: 0.1032 - accuracy: 0.4252\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1034 - accuracy: 0.4176\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1027 - accuracy: 0.4196\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 12s 58ms/step - loss: 0.1021 - accuracy: 0.4227\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 13s 62ms/step - loss: 0.1015 - accuracy: 0.4143\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 12s 60ms/step - loss: 0.1025 - accuracy: 0.4215\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1018 - accuracy: 0.4230\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1013 - accuracy: 0.4233\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1037 - accuracy: 0.4552\n",
      "Loss:  0.10366062819957733\n",
      "Accuracy:  0.4551820755004883\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 12s 59ms/step - loss: 0.1036 - accuracy: 0.4199\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 13s 62ms/step - loss: 0.1020 - accuracy: 0.4291\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1035 - accuracy: 0.4176\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1029 - accuracy: 0.4201\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1028 - accuracy: 0.4093\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 12s 59ms/step - loss: 0.1025 - accuracy: 0.4166\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 12s 60ms/step - loss: 0.1025 - accuracy: 0.4204\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1022 - accuracy: 0.4283\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1019 - accuracy: 0.4249\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 62ms/step - loss: 0.1025 - accuracy: 0.4286\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0993 - accuracy: 0.4538\n",
      "Loss:  0.09928207844495773\n",
      "Accuracy:  0.45378151535987854\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1022 - accuracy: 0.4298\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 12s 58ms/step - loss: 0.1021 - accuracy: 0.4208\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1016 - accuracy: 0.4178\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1011 - accuracy: 0.4131\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1016 - accuracy: 0.4164\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 12s 58ms/step - loss: 0.1024 - accuracy: 0.4055\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1013 - accuracy: 0.4167\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1015 - accuracy: 0.4265\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1020 - accuracy: 0.4275\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1022 - accuracy: 0.4233\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1043 - accuracy: 0.4544\n",
      "Loss:  0.10434360057115555\n",
      "Accuracy:  0.4544179439544678\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 12s 58ms/step - loss: 0.1015 - accuracy: 0.4214\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1018 - accuracy: 0.4443\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1028 - accuracy: 0.4359\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1011 - accuracy: 0.4339\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1014 - accuracy: 0.4488\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 12s 58ms/step - loss: 0.1012 - accuracy: 0.4543\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1010 - accuracy: 0.4393\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1022 - accuracy: 0.4410\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 12s 59ms/step - loss: 0.1014 - accuracy: 0.4427\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1005 - accuracy: 0.4267\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1045 - accuracy: 0.4474\n",
      "Loss:  0.10452216118574142\n",
      "Accuracy:  0.4474053382873535\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1033 - accuracy: 0.4152\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1025 - accuracy: 0.4233\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 60ms/step - loss: 0.1020 - accuracy: 0.4298\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1018 - accuracy: 0.4248\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1015 - accuracy: 0.4381\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 12s 59ms/step - loss: 0.1008 - accuracy: 0.4142\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1014 - accuracy: 0.4149\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1010 - accuracy: 0.4103\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 12s 58ms/step - loss: 0.1011 - accuracy: 0.4373\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1016 - accuracy: 0.4337\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1067 - accuracy: 0.4320\n",
      "Loss:  0.10670392215251923\n",
      "Accuracy:  0.4319775700569153\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1019 - accuracy: 0.4267\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 12s 59ms/step - loss: 0.1011 - accuracy: 0.4259\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1008 - accuracy: 0.4269\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1015 - accuracy: 0.4255\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1013 - accuracy: 0.4242\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 12s 59ms/step - loss: 0.1007 - accuracy: 0.4262\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1002 - accuracy: 0.4203\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 12s 58ms/step - loss: 0.1011 - accuracy: 0.4314\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1001 - accuracy: 0.4560\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1005 - accuracy: 0.4479\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1079 - accuracy: 0.4502\n",
      "Loss:  0.10785835236310959\n",
      "Accuracy:  0.4502103924751282\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1023 - accuracy: 0.4407\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 12s 58ms/step - loss: 0.1031 - accuracy: 0.4510\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1027 - accuracy: 0.4348\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1024 - accuracy: 0.4396\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1054 - accuracy: 0.4403\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 11s 57ms/step - loss: 0.1037 - accuracy: 0.4314\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1029 - accuracy: 0.4294\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1024 - accuracy: 0.4429\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1025 - accuracy: 0.4480\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 12s 57ms/step - loss: 0.1025 - accuracy: 0.4537\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0898 - accuracy: 0.4446\n",
      "Loss:  0.08975695073604584\n",
      "Accuracy:  0.44460028409957886\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1008 - accuracy: 0.44120s - l\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1012 - accuracy: 0.4401\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 59ms/step - loss: 0.1019 - accuracy: 0.4332\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1011 - accuracy: 0.4544\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1020 - accuracy: 0.4297\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 14s 70ms/step - loss: 0.1013 - accuracy: 0.4290\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 16s 78ms/step - loss: 0.1010 - accuracy: 0.4286\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 67ms/step - loss: 0.1018 - accuracy: 0.4375\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1013 - accuracy: 0.4360\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1011 - accuracy: 0.4381\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1024 - accuracy: 0.4628\n",
      "Loss:  0.10237181186676025\n",
      "Accuracy:  0.46283310651779175\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1013 - accuracy: 0.4295\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 14s 68ms/step - loss: 0.1020 - accuracy: 0.4317\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1011 - accuracy: 0.4322\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1018 - accuracy: 0.4404\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1014 - accuracy: 0.4448\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1017 - accuracy: 0.4328\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1019 - accuracy: 0.4208\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1026 - accuracy: 0.4460\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1016 - accuracy: 0.4345\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1014 - accuracy: 0.4315\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0986 - accuracy: 0.4755\n",
      "Loss:  0.09855745732784271\n",
      "Accuracy:  0.4754558205604553\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1008 - accuracy: 0.4382\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 0.1010 - accuracy: 0.4297\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 12s 61ms/step - loss: 0.1005 - accuracy: 0.4317\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1013 - accuracy: 0.4435\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1004 - accuracy: 0.4294\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 13s 63ms/step - loss: 0.1007 - accuracy: 0.4406\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 14s 68ms/step - loss: 0.1005 - accuracy: 0.4521\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 64ms/step - loss: 0.1011 - accuracy: 0.4259\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 12s 62ms/step - loss: 0.1007 - accuracy: 0.4370\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 66ms/step - loss: 0.1007 - accuracy: 0.4322\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1057 - accuracy: 0.4783\n",
      "Loss:  0.10571110248565674\n",
      "Accuracy:  0.47826087474823\n"
     ]
    }
   ],
   "source": [
    "accr, losses = [], []\n",
    "y_pred,y_true = [], []\n",
    "modelKFOLD = utils.build_model(NUM_WORDS)\n",
    "kf = RepeatedKFold(n_splits=N_SPLITS,n_repeats=N_REPEATS,random_state=RANDOM_STATE)\n",
    "\n",
    "for train_index, val_index in kf.split(x_padded_train):\n",
    "    X, X_val = x_padded_train[train_index], x_padded_train[val_index]\n",
    "    y, y_val = y_train[train_index], y_train[val_index]\n",
    "    modelKFOLD.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
    "    pred = modelKFOLD.evaluate(X_val,y_val)\n",
    "    prediction = modelKFOLD.predict(X_val)\n",
    "    print(\"Loss: \",pred[0])\n",
    "    print(\"Accuracy: \",pred[1])\n",
    "    losses.append(pred[0])\n",
    "    accr.append(pred[1])\n",
    "    y_pred.append(prediction)\n",
    "    y_true.append(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "experimental-template",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 0. 1. 1.]\n",
      "[1 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[0][0].round())\n",
    "print(y_true[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "corporate-wednesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12279526169101397\n",
      "0.43713180522123973\n"
     ]
    }
   ],
   "source": [
    "print(sum(losses)/len(losses))\n",
    "print(sum(accr)/len(accr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# For each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "                                                        y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(Y_test[:, i], y_score[:, i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
