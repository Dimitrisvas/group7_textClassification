{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0746eec4f0cf2bd2bd143a4eb10480580d722f553ed0fc03fc42076491106f879",
   "display_name": "Python 3.8.8 64-bit ('grp7_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### 6481784 - Group 7 Individual Experimentation\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pickle\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Dropout, Conv1D, GlobalMaxPooling1D, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Constants\n",
    "EPOCHS = 30\n",
    "INIT_LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in pre-processed dataset\n",
    "x_text_train = pickle.load(open('../comment_lemma.pickle', 'rb'))\n",
    "x_text_test_unprocessed = pickle.load(open('../balanced_test_dataset.pickle', 'rb'))\n",
    "y_train = pd.read_pickle('../balanced_dataset.pickle').drop(columns='comment_text')\n",
    "y_test = pd.read_pickle('../balanced_test_dataset.pickle').drop(columns='comment_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_text_test = pickle.load(open('test_dataset.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 20000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words)\n",
    "tokenizer.fit_on_texts(x_text_train)\n",
    "corpus = tokenizer.word_index\n",
    "reverse_corpus = dict(map(reversed, corpus.items()))\n",
    "x_sequences_train = tokenizer.texts_to_sequences(x_text_train)\n",
    "X_t = keras.preprocessing.sequence.pad_sequences(x_sequences_train, maxlen=max_len)\n",
    "X_t = np.array(X_t)\n",
    "np.random.shuffle(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sequences_test = tokenizer.texts_to_sequences(x_text_test)\n",
    "X_te = keras.preprocessing.sequence.pad_sequences(x_sequences_test, maxlen=max_len)\n",
    "X_te = np.array(X_te)\n",
    "np.random.shuffle(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = 0.2\n",
    "num_validation_samples = int(val_split*X_t.shape[0])\n",
    "x_train = X_t[: -num_validation_samples]\n",
    "y_train = y_train[: -num_validation_samples]\n",
    "x_val = X_t[-num_validation_samples: ]\n",
    "y_val = y_train[-num_validation_samples: ]"
   ]
  },
  {
   "source": [
    "### Base Model Definition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(num_words, 128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3))\n",
    "model.add(Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "#adam = tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "source": [
    "### Base Model Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "96/96 [==============================] - 13s 133ms/step - loss: 0.6030 - accuracy: 0.3267 - val_loss: 0.4808 - val_accuracy: 0.0295\n",
      "Epoch 2/15\n",
      "96/96 [==============================] - 13s 136ms/step - loss: 0.5927 - accuracy: 0.3281 - val_loss: 0.4823 - val_accuracy: 0.0028\n",
      "Epoch 3/15\n",
      "96/96 [==============================] - 13s 131ms/step - loss: 0.5845 - accuracy: 0.3309 - val_loss: 0.4853 - val_accuracy: 0.5098\n",
      "Epoch 4/15\n",
      "96/96 [==============================] - 13s 136ms/step - loss: 0.5325 - accuracy: 0.4012 - val_loss: 0.4813 - val_accuracy: 0.4937\n",
      "Epoch 5/15\n",
      "96/96 [==============================] - 14s 142ms/step - loss: 0.4418 - accuracy: 0.4725 - val_loss: 0.6329 - val_accuracy: 0.6767\n",
      "Epoch 6/15\n",
      "96/96 [==============================] - 12s 127ms/step - loss: 0.3900 - accuracy: 0.5035 - val_loss: 0.6796 - val_accuracy: 0.5554\n",
      "Epoch 7/15\n",
      "96/96 [==============================] - 12s 127ms/step - loss: 0.3541 - accuracy: 0.4928 - val_loss: 0.7072 - val_accuracy: 0.5820\n",
      "Epoch 8/15\n",
      "96/96 [==============================] - 13s 132ms/step - loss: 0.3181 - accuracy: 0.4739 - val_loss: 0.6896 - val_accuracy: 0.4523\n",
      "Epoch 9/15\n",
      "96/96 [==============================] - 13s 130ms/step - loss: 0.2910 - accuracy: 0.4651 - val_loss: 0.7009 - val_accuracy: 0.4839\n",
      "Epoch 10/15\n",
      "96/96 [==============================] - 13s 139ms/step - loss: 0.2647 - accuracy: 0.4502 - val_loss: 0.7771 - val_accuracy: 0.4649\n",
      "Epoch 11/15\n",
      "96/96 [==============================] - 17s 173ms/step - loss: 0.2446 - accuracy: 0.4450 - val_loss: 0.7344 - val_accuracy: 0.3128\n",
      "Epoch 12/15\n",
      "96/96 [==============================] - 14s 143ms/step - loss: 0.2189 - accuracy: 0.4367 - val_loss: 0.8297 - val_accuracy: 0.3927\n",
      "Epoch 13/15\n",
      "96/96 [==============================] - 14s 144ms/step - loss: 0.1971 - accuracy: 0.4331 - val_loss: 0.8261 - val_accuracy: 0.3240\n",
      "Epoch 14/15\n",
      "96/96 [==============================] - 13s 138ms/step - loss: 0.1844 - accuracy: 0.4443 - val_loss: 0.8611 - val_accuracy: 0.3534\n",
      "Epoch 15/15\n",
      "96/96 [==============================] - 13s 134ms/step - loss: 0.1688 - accuracy: 0.4276 - val_loss: 0.9738 - val_accuracy: 0.3499\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b44fc49a60>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs=15, batch_size=60,  validation_data=(x_val, y_val))"
   ]
  },
  {
   "source": [
    "### Experiment Setup 1 - Loss Function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Experiment Setup 1 Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_te)\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = y_pred.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_train[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]]\n",
    "y_true = y_true.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 1 1 0 1 1]\n[0.55544668 0.34327281 0.58660328 0.10950568 0.5551545  0.25217932]\n"
     ]
    }
   ],
   "source": [
    "index = 257\n",
    "print(y_true[index])\n",
    "\n",
    "print(y_pred[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}